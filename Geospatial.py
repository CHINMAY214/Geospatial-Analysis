import streamlit as st
import pandas as pd
import folium
from folium.plugins import HeatMap
from streamlit_folium import st_folium
import yaml

# âœ… Set Streamlit page configuration
st.set_page_config(page_title="Sales Heatmap Analysis", layout="wide")

# âœ… Load user credentials from YAML file
with open("credentials.yaml", "r") as file:
    config = yaml.safe_load(file)

# âœ… Function to check login
def authenticate(username, password):
    for user, details in config["credentials"].items():
        if details["username"] == username and details["password"] == password:
            return True
    return False

# âœ… Initialize session state for login
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "username" not in st.session_state:
    st.session_state.username = ""

# --- LOGIN PAGE ---
if not st.session_state.logged_in:
    st.title("ğŸ” Login to Access the Dashboard")
    username = st.text_input("Username")
    password = st.text_input("Password", type="password")

    if st.button("Login"):
        if authenticate(username, password):
            st.session_state.logged_in = True
            st.session_state.username = username
            st.success("âœ… Login successful!")
            st.rerun()  # âœ… Restart app after login
        else:
            st.error("âŒ Invalid username or password!")

else:
    # --- DASHBOARD STARTS HERE ---
    st.sidebar.success(f"Welcome, {st.session_state.username} ğŸ‘‹")

    # âœ… Logout button
    if st.sidebar.button("Logout"):
        st.session_state.logged_in = False
        st.session_state.username = ""
        st.rerun()

    # âœ… Streamlit app title
    st.title("ğŸ“ Sales Heatmap with High-Sales City Markers")

    # âœ… File upload section
    st.sidebar.markdown("### ğŸ“‚ Upload Pre-Merged Dataset")
    uploaded_file = st.sidebar.file_uploader("Upload CSV File", type=["csv"])

    if uploaded_file:
        # âœ… Load dataset
        data = pd.read_csv(uploaded_file, encoding="ISO-8859-1")

        # âœ… Ensure required columns exist
        required_columns = {"City", "Country", "Sales", "Latitude", "Longitude"}
        if not required_columns.issubset(set(data.columns)):
            st.error(f"âŒ Dataset is missing required columns! Expected: {required_columns}")
            st.stop()

        # âœ… Drop rows with missing Latitude/Longitude
        data = data.dropna(subset=["Latitude", "Longitude"])

        # âœ… Check if dataset has valid locations
        if data.empty:
            st.error("âŒ No valid location data available. Please check your dataset.")
            st.stop()

        # âœ… Compute the map center
        map_center = [data["Latitude"].mean(), data["Longitude"].mean()]
        sales_map = folium.Map(location=map_center, zoom_start=3)

        # âœ… Prepare data for the heatmap
        heat_data = data[['Latitude', 'Longitude', 'Sales']].values.tolist()
        HeatMap(heat_data, radius=10, blur=15, max_zoom=1).add_to(sales_map)

        # âœ… Identify the top 10 high-sales cities
        top_10_sales_cities = data.nlargest(10, 'Sales')[["City", "Country", "Latitude", "Longitude", "Sales"]]

        # âœ… Add markers for the top 10 high-sales cities
        for _, row in top_10_sales_cities.iterrows():
            folium.Marker(
                location=[row["Latitude"], row["Longitude"]],
                popup=f"{row['City']}, {row['Country']}<br>Sales: ${row['Sales']:,}",
                icon=folium.Icon(color="red", icon="info-sign")  # Red marker for high-sales cities
            ).add_to(sales_map)

        # âœ… Display Map inside Streamlit
        st.markdown("<h2>ğŸ“Š Sales Heatmap</h2>", unsafe_allow_html=True)
        st_folium(sales_map, width=1000, height=600)

        # âœ… Display Top 10 High-Sales Cities Table
        st.markdown("<h2>ğŸ† Top 10 High-Sales Cities</h2>", unsafe_allow_html=True)
        st.dataframe(top_10_sales_cities)

    else:
        st.warning("âš ï¸ Please upload a CSV file to proceed.")
